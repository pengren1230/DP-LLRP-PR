# -*- coding: utf-8 -*-
"""myopic_modification_version_100-5-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M5M2QAezTMVJy7bXkzIrOUh9Jf96ifWw
"""

"""
LLRP Fast ADP Rollout (non-myopic) — New 5-depot / 100-customer dataset
- Same method as your previous file: nearest-K + light Clarke–Wright candidates,
  exact Held–Karp mini-TSP (k<=9), optional PyTorch DeepSets surrogate,
  and a non-myopic tail-value lookahead with discounting.
"""

import math, itertools, hashlib, random, time
from functools import lru_cache
import numpy as np

# -----------------------------
# User-specified instance (5 depots, 100 customers)
# -----------------------------

# Depots (order preserved; names D1..D5)
_depot_coords = [
    (1, 13),
    (46, 4),
    (2, 3),
    (13, 19),
    (3, 37),
]

# Customers (100)
_customer_coords = [
   (31, 6),
   (36, 20),
   (9, 19),
   (47, 42),
   (28, 20),
   (38, 43),
   (41, 4),
   (36, 30),
   (4, 10),
   (43, 16),
   (33, 45),
   (39, 30),
   (6, 40),
   (50, 20),
   (48, 14),
   (34, 34),
   (49, 3),
   (26, 14),
   (28, 44),
   (21, 38),
   (34, 11),
   (41, 32),
   (44, 46),
   (27, 48),
   (2, 36),
   (34, 32),
   (50, 27),
   (36, 26),
   (16, 17),
   (8, 10),
   (45, 28),
   (49, 11),
   (28, 10),
   (9, 10),
   (39, 50),
   (33, 31),
   (20, 8),
   (39, 48),
   (29, 3),
   (43, 32),
   (34, 9),
   (42, 40),
   (25, 49),
   (27, 4),
   (29, 37),
   (28, 32),
   (42, 8),
   (18, 22),
   (20, 33),
   (28, 48),
   (35, 19),
   (49, 36),
   (49, 35),
   (25, 25),
   (6, 5),
   (6, 24),
   (38, 28),
   (24, 27),
   (49, 48),
   (7, 44),
   (18, 44),
   (45, 46),
   (23, 15),
   (17, 47),
   (47, 18),
   (5, 18),
   (5, 47),
   (41, 47),
   (5, 2),
   (24, 49),
   (32, 46),
   (48, 43),
   (20, 35),
   (20, 38),
   (9, 29),
   (29, 2),
   (26, 20),
   (26, 11),
   (16, 26),
   (34, 43),
   (1, 2),
   (48, 14),
   (34, 44),
   (41, 32),
   (41, 13),
   (46, 7),
   (7, 34),
   (8, 34),
   (9, 11),
   (3, 15),
   (35, 9),
   (1, 11),
   (17, 34),
   (20, 42),
   (46, 30),
   (9, 43),
   (45, 8),
   (45, 31),
   (50, 37),
   (38, 39),
]

# Demands (100; same order as above)
_customer_demands = [
18,17,14,11,15,16,11,12,14,19,17,16,20,13,11,17,17,19,12,13,
20,14,13,16,13,16,18,14,13,11,16,19,20,16,19,14,16,18,11,19,
12,16,20,12,12,13,12,18,20,20,15,12,16,15,12,18,15,13,17,15,
20,14,15,17,13,12,17,19,16,20,11,13,17,19,15,18,12,16,16,16,
13,19,20,20,18,20,14,20,18,13,20,15,15,15,14,17,20,18,19,18
]

# Build dicts: depots D*, customers C*
depots = {f"D{i+1}": (float(x), float(y)) for i,(x,y) in enumerate(_depot_coords)}
customers = {f"C{i+1}": {"coord": (float(x), float(y)), "demand": int(_customer_demands[i])}
             for i,(x,y) in enumerate(_customer_coords)}

# -----------------------------
# Core parameters
# -----------------------------
vehicle_capacity = 70
depot_capacity_per_depot = 770
discount_factor = 0.9
print(f"[INFO] Using discount_factor = {discount_factor}")

# -----------------------------
# Planning horizon & arrivals
# -----------------------------
time_horizon = 5  # main planning window; cleanup continues if needed

# Randomized appearance times across horizon (seeded, reproducible).
#  - ~50% at t=0, 20% at t=1, 15% at t=2, 10% at t=3, 5% at t=4
rng = random.Random(2025)
customer_ids = [f"C{i}" for i in range(1, len(customers)+1)]
idxs = list(range(len(customer_ids))); rng.shuffle(idxs)

cuts = [int(0.50*len(idxs)), int(0.70*len(idxs)), int(0.85*len(idxs)), int(0.95*len(idxs)), len(idxs)]
bins = [idxs[:cuts[0]], idxs[cuts[0]:cuts[1]], idxs[cuts[1]:cuts[2]], idxs[cuts[2]:cuts[3]], idxs[cuts[3]:cuts[4]]]
appear_time = {}
for t, bucket in enumerate(bins):
    for i in bucket:
        appear_time[customer_ids[i]] = t

base_demands = {c: customers[c]["demand"] for c in customers}

# Example demand override: bump C1 to 20 from t>=2 (optional; feel free to change/remove)
demand_overrides = {"C1": [(2, 20)]}

# -----------------------------
# CRN & stochastic arc options (off by default)
# -----------------------------
GLOBAL_SEED = 12345
SCENARIO_ID = 0
LAM   = 0.0  # Poisson demand growth per period (0 disables)
SIGMA = 0.0  # Lognormal arc noise stdev (0 disables)
K_STOCHASTIC_LEGS = 0
MULT_LOWER = 1.0
MULT_UPPER = 1.5

def _crn_seed(*keys, base_seed=GLOBAL_SEED, scenario=SCENARIO_ID):
    h = hashlib.blake2b(digest_size=8)
    h.update(("|".join(map(str, (int(base_seed), int(scenario)) + keys))).encode())
    return int.from_bytes(h.digest(), "little") & 0xFFFFFFFF

# -----------------------------
# Indexing & distances
# -----------------------------
depot_names = list(depots.keys())
D = len(depot_names)
N = len(customers)

CUST_OFFSET = D
node_xy = np.array([depots[d] for d in depot_names] +
                   [customers[c]["coord"] for c in customer_ids], dtype=float)
diff = node_xy[:, None, :] - node_xy[None, :, :]
euclid = np.sqrt((diff ** 2).sum(-1))
name_to_cidx = {cid: (CUST_OFFSET + i) for i, cid in enumerate(customer_ids)}

# -----------------------------
# Demand over time (CRN-stable)
# -----------------------------
def demand_at_time(t, cid):
    t0 = appear_time.get(cid, 0)
    if t < t0:
        return None
    base = base_demands[cid]
    start = t0
    for (tt, new_base) in sorted(demand_overrides.get(cid, [])):
        if t >= tt:
            base = new_base
            start = tt
        else:
            break
    inc = 0
    if LAM > 0.0:
        for tau in range(start, t):
            rng_np = np.random.default_rng(_crn_seed("dem", cid, tau))
            inc += rng_np.poisson(LAM)
    return int(base + inc)

# -----------------------------
# Stochastic legs & arc noise (optional)
# -----------------------------
def _choose_stochastic_legs(k=K_STOCHASTIC_LEGS):
    if k <= 0:
        return set(), {}
    total_nodes = D + N
    pairs = [(i, j) for i in range(total_nodes) for j in range(i + 1, total_nodes)]
    rng_np = np.random.default_rng(_crn_seed("choose_legs"))
    k = min(k, len(pairs))
    idxs2 = rng_np.choice(len(pairs), size=k, replace=False)
    chosen = [pairs[i] for i in idxs2]
    fac = {}
    for a, b in chosen:
        rng_ab = np.random.default_rng(_crn_seed("leg_factor", a, b))
        u = rng_ab.random()
        f = MULT_LOWER + (MULT_UPPER - MULT_LOWER) * float(u)
        fac[(a, b)] = f
    return set(chosen), fac

_selected_legs, _leg_factor = _choose_stochastic_legs()

def _travel_factor(i, j):
    a, b = (i, j) if i <= j else (j, i)
    return _leg_factor.get((a, b), 1.0)

def _arc_noise(i, j):
    if SIGMA <= 0.0:
        return 1.0
    a, b = (i, j) if i <= j else (j, i)
    rng_np = np.random.default_rng(_crn_seed("arc", a, b))
    mu = -0.5 * (SIGMA ** 2)
    return float(rng_np.lognormal(mean=mu, sigma=SIGMA))

# -----------------------------
# Precompute per-scenario (once)
# -----------------------------
def precompute_scenario(time_horizon):
    demand = {t: {cid: int(demand_at_time(t, cid) or 0) for cid in customer_ids}
              for t in range(time_horizon + 1)}
    W = euclid.copy().astype(float)
    for i in range(W.shape[0]):
        for j in range(i + 1, W.shape[1]):
            w = float(euclid[i, j]) * _arc_noise(i, j) * _travel_factor(i, j)
            W[i, j] = W[j, i] = w
    return W, demand

W, demand_table = precompute_scenario(time_horizon)

COORD_SCALE = max(
    max(x for (x, _) in _depot_coords + _customer_coords),
    max(y for (_, y) in _depot_coords + _customer_coords),
    1
)
DIST_SCALE = float(np.max(W)) if W.size > 0 else 1.0
DEMAND_SCALE = max(base_demands.values()) if base_demands else 1

# -----------------------------
# Held–Karp exact mini-TSP (k <= 9) + latency wrapper
# -----------------------------
def held_karp_latency(W, depot_idx, subset_idx):
    k = len(subset_idx)
    if k == 0:
        return 0.0
    if k == 1:
        c = subset_idx[0]
        return W[depot_idx, c] + W[c, depot_idx]

    @lru_cache(None)
    def dp(mask, j):
        if mask == (1 << j):
            return W[depot_idx, subset_idx[j]]
        prev = mask ^ (1 << j)
        best = float('inf')
        for i in range(k):
            if i == j or not (prev & (1 << i)):
                continue
            cand = dp(prev, i) + W[subset_idx[i], subset_idx[j]]
            if cand < best:
                best = cand
        return best

    FULL = (1 << k) - 1
    best = float('inf')
    for j in range(k):
        cand = dp(FULL, j) + W[subset_idx[j], depot_idx]
        if cand < best:
            best = cand
    return best

# -----------------------------
# Optional PyTorch DeepSets surrogate
# -----------------------------
try:
    import torch, torch.nn as nn, torch.optim as optim
    TORCH_OK = True
except Exception:
    TORCH_OK = False

if TORCH_OK:
    class DeepSet(nn.Module):
        def __init__(self, in_dim=8, hid=64):
            super().__init__()
            self.phi = nn.Sequential(nn.Linear(in_dim, hid), nn.ReLU(),
                                     nn.Linear(hid, hid), nn.ReLU())
            self.rho = nn.Sequential(nn.Linear(hid + 2, 64), nn.ReLU(),
                                     nn.Linear(64, 32), nn.ReLU(),
                                     nn.Linear(32, 1))

        def forward(self, depot_vec, node_feats):
            outs = []
            for X in node_feats:
                if X.numel() > 0:
                    s = self.phi(X).sum(dim=0)
                else:
                    s = torch.zeros(64, device=depot_vec.device)
                outs.append(self.rho(torch.cat([s, depot_vec.squeeze(0)], dim=-1)))
            return torch.vstack(outs).squeeze(-1)

    class Surrogate(nn.Module):
        """DeepSets-style value function approximator."""

        def __init__(self, customer_feat_dim=8, global_feat_dim=7, hidden=128):
            super().__init__()
            self.hidden = hidden
            self.customer_encoder = nn.Sequential(
                nn.Linear(customer_feat_dim, hidden), nn.ReLU(),
                nn.Linear(hidden, hidden), nn.ReLU()
            )
            self.value_head = nn.Sequential(
                nn.Linear(hidden + global_feat_dim, hidden), nn.ReLU(),
                nn.Linear(hidden, hidden // 2), nn.ReLU(),
                nn.Linear(hidden // 2, 1)
            )

        def forward(self, global_feat, customer_feats):
            if customer_feats is None or customer_feats.numel() == 0:
                agg = torch.zeros((global_feat.shape[0], self.hidden), device=global_feat.device)
            else:
                if customer_feats.dim() == 1:
                    customer_feats = customer_feats.unsqueeze(0)
                enc = self.customer_encoder(customer_feats)
                agg = enc.sum(dim=0, keepdim=True)
                if agg.shape[0] != global_feat.shape[0]:
                    agg = agg.expand(global_feat.shape[0], -1)
            x = torch.cat([global_feat, agg], dim=-1)
            return self.value_head(x).squeeze(-1)

def make_features(d_idx, subset_idx):
    dxy = node_xy[d_idx]
    rows = []
    for c in subset_idx:
        xy = node_xy[c]
        dx, dy = xy[0] - dxy[0], xy[1] - dxy[1]
        r = math.hypot(dx, dy)
        rows.append([dx, dy, r, r*r, 1.0, 0.0, 0.0, 0.0])
    if TORCH_OK:
        X = torch.tensor(rows, dtype=torch.float32)
        dep = torch.tensor([dxy.tolist()], dtype=torch.float32)
        return dep, X
    return None, None

if TORCH_OK:
    def build_state_tensors(t_next, remaining, inv_state, r_state, v_state):
        """Encode ADP state into tensors for the value surrogate."""
        global_total_inv = sum(inv_state.get(d, 0.0) for d in depot_names)
        total_cap = 0.0
        for d in depot_names:
            residual = max(float(r_state.get(d, 0.0)), 0.0)
            fleet = float(v_state.get(d, 0)) * vehicle_capacity
            total_cap += residual + fleet
        total_rem_demand = 0.0
        features = []
        nearest_dists = []
        for cid in remaining:
            cidx = name_to_cidx[cid]
            xy = node_xy[cidx]
            demand_now = demand_table[min(t_next, time_horizon - 1)][cid]
            total_rem_demand += demand_now
            nearest_idx = min(range(len(depot_names)), key=lambda idx: W[idx, cidx]) if depot_names else 0
            nearest_name = depot_names[nearest_idx] if depot_names else None
            dist_nearest = W[nearest_idx, cidx] if depot_names else 0.0
            nearest_dists.append(dist_nearest)
            time_since = max(0, t_next - appear_time.get(cid, 0))
            inv_nearest = inv_state.get(nearest_name, 0.0) if nearest_name else 0.0
            cap_nearest = max(float(r_state.get(nearest_name, 0.0)), 0.0) if nearest_name else 0.0
            if nearest_name and cap_nearest <= 0 and v_state.get(nearest_name, 0) > 0:
                cap_nearest = float(vehicle_capacity)
            features.append([
                float(xy[0]) / COORD_SCALE,
                float(xy[1]) / COORD_SCALE,
                float(demand_now) / max(DEMAND_SCALE, 1),
                float(time_since) / max(time_horizon, 1),
                float(dist_nearest) / max(DIST_SCALE, 1.0),
                inv_nearest / max(depot_capacity_per_depot, 1),
                cap_nearest / max(vehicle_capacity, 1),
                1.0 if appear_time.get(cid, 0) <= t_next else 0.0,
            ])

        avg_nearest = (sum(nearest_dists) / len(nearest_dists)) if nearest_dists else 0.0
        global_feat = torch.tensor([
            float(t_next) / max(time_horizon, 1),
            len(remaining) / max(len(customer_ids), 1),
            total_rem_demand / (max(len(customer_ids), 1) * max(DEMAND_SCALE, 1)),
            global_total_inv / (len(depot_names) * max(depot_capacity_per_depot, 1)),
            total_cap / (len(depot_names) * vehicle_capacity if depot_names else 1),
            avg_nearest / max(DIST_SCALE, 1.0),
            max(inv_state.values()) / max(depot_capacity_per_depot, 1) if inv_state else 0.0,
        ], dtype=torch.float32).unsqueeze(0)

        if features:
            cust_tensor = torch.tensor(features, dtype=torch.float32)
        else:
            cust_tensor = torch.zeros((0, 8), dtype=torch.float32)
        return global_feat, cust_tensor
else:
    def build_state_tensors(*args, **kwargs):
        return None, None

def sample_pairs(num_pairs=1200, max_set=6, seed=1):
    rng_loc = random.Random(seed)
    pairs = []
    for _ in range(num_pairs):
        d_idx = rng_loc.randrange(D)
        k = rng_loc.randrange(1, min(max_set, N) + 1)
        subset = sorted(rng_loc.sample(range(CUST_OFFSET, CUST_OFFSET + N), k))
        y = held_karp_latency(W, d_idx, subset)
        if TORCH_OK:
            dep, X = make_features(d_idx, subset)
            pairs.append((dep, X, y))
    return pairs

_latency_surrogate = None
if TORCH_OK:
    def train_surrogate(epochs=6, lr=2e-3):
        model = DeepSet()
        opt = optim.Adam(model.parameters(), lr=lr)
        train = sample_pairs(1000, 6, seed=1)
        model.train()
        for ep in range(epochs):
            for dep, X, y in train:
                opt.zero_grad()
                pred = model(dep, [X])
                loss = (pred.squeeze() - torch.tensor([y], dtype=torch.float32)).pow(2).mean()
                loss.backward(); opt.step()
        model.eval(); return model
    _latency_surrogate = train_surrogate()
else:
    _latency_surrogate = None

EXACT_K = 9  # Held–Karp cutover
DEBUG_DIAG = True  # print lightweight diagnostics

@lru_cache(None)
def latency_fast_cached(d_idx, subset_tuple):
    ss = list(subset_tuple)
    k = len(ss)
    if k <= EXACT_K:
        return float(held_karp_latency(W, d_idx, ss))
    if _latency_surrogate is not None:
        dep, X = make_features(d_idx, ss)
        with torch.no_grad():
            y = float(_latency_surrogate(dep, [X]).squeeze())
        return y
    # Fallback heuristic if no surrogate
    cur = min(ss, key=lambda u: W[d_idx, u])
    dist = W[d_idx, cur]
    unused = set(ss); unused.remove(cur)
    while unused:
        nxt = min(unused, key=lambda u: W[cur, u])
        dist += W[cur, nxt]; cur = nxt; unused.remove(cur)
    dist += W[cur, d_idx]
    return float(dist)

def latency_fast(d_idx, subset_idx_list):
    return latency_fast_cached(d_idx, tuple(sorted(subset_idx_list)))

# -----------------------------
# Candidate generation
# -----------------------------
K_NEAR     = 15
CAND_LIMIT = 80
MAX_ROUTE_SIZE = 5

def nearest_k(avail, d_idx, K=K_NEAR):
    return sorted(avail, key=lambda cid: W[d_idx, name_to_cidx[cid]])[:K]

def cw_candidates(nearest_list, d_idx, cap, inv, t, limit=CAND_LIMIT):
    routes = [[c] for c in nearest_list if 0 < demand_table[t][c] <= min(cap, inv)]
    # pairwise savings
    sav = []
    for i in range(len(nearest_list)):
        for j in range(i + 1, len(nearest_list)):
            ci, cj = nearest_list[i], nearest_list[j]
            ni, nj = name_to_cidx[ci], name_to_cidx[cj]
            sav.append((W[d_idx, ni] + W[d_idx, nj] - W[ni, nj], ci, cj))
    sav.sort(reverse=True)

    cand = []
    def fits(route):
        dem = sum(demand_table[t][c] for c in route)
        return (dem > 0) and (dem <= cap) and (dem <= inv)

    for s, ci, cj in sav:
        ri = next((r for r in routes if r[0] == ci or r[-1] == ci), None)
        rj = next((r for r in routes if r[0] == cj or r[-1] == cj), None)
        if not ri or not rj or ri is rj:
            continue
        merged = None
        for v in (ri + rj, list(reversed(ri)) + rj,
                  ri + list(reversed(rj)), list(reversed(ri)) + list(reversed(rj))):
            if fits(v):
                merged = v; break
        if merged:
            routes.remove(ri); routes.remove(rj); routes.append(merged)
            cand.append(merged)
            if len(cand) >= limit:
                break

    extras = []
    for r in routes:
        Lmax = min(len(r), MAX_ROUTE_SIZE)
        for L in range(1, Lmax + 1):
            seg = r[:L]
            if fits(seg):
                extras.append(seg)

    seen, uniq = set(), []
    for s in cand + extras:
        key = frozenset(s)
        if key not in seen:
            seen.add(key); uniq.append(s)
        if len(uniq) >= limit:
            break
    return uniq

# -----------------------------
# Tail value estimator (non-myopic lookahead)
# -----------------------------
def estimate_tail_value(remaining, inv_left, r_left, v_left, t_start_next, per_depot_iters=2):
    """Greedy proxy for undiscounted cost-to-go to complete remaining set."""
    rem = list(remaining)
    est = 0.0
    if not rem:
        return 0.0
    r_tmp = dict(r_left)
    v_tmp = dict(v_left)
    inv_tmp = dict(inv_left)

    for dname in depot_names:
        iters = per_depot_iters
        while iters > 0:
            if r_tmp[dname] <= 0 and v_tmp[dname] > 0:
                v_tmp[dname] -= 1
                r_tmp[dname] = vehicle_capacity
            cap = r_tmp[dname] if r_tmp[dname] > 0 else (vehicle_capacity if v_tmp[dname] > 0 else 0)
            inv = inv_tmp[dname]
            if cap <= 0 or inv <= 0:
                break
            d_idx = depot_names.index(dname)
            pool  = nearest_k(rem, d_idx, K_NEAR)
            t_eff = min(t_start_next, time_horizon - 1)
            cands = cw_candidates(pool, d_idx, cap, inv, t_eff, CAND_LIMIT)
            best_local = None  # (lat, subset_names, dem)
            for subset_names in cands:
                dem = sum(demand_table[t_eff][c] for c in subset_names)
                if dem <= 0 or dem > cap or dem > inv:
                    continue
                subset_idx = [name_to_cidx[c] for c in subset_names]
                lat = latency_fast(d_idx, subset_idx)
                cand = (lat, subset_names, dem)
                if best_local is None or lat < best_local[0] or (lat == best_local[0] and dem > best_local[2]):
                    best_local = cand
            if best_local is None:
                nearest, bestd = None, float('inf')
                for cid in rem:
                    q = demand_table[t_eff][cid]
                    if q <= 0 or q > cap or q > inv:
                        continue
                    cidx = name_to_cidx[cid]
                    d = W[d_idx, cidx]
                    if d < bestd:
                        bestd, nearest = d, cid
                if nearest is None:
                    break

                subset_names = [nearest]
                subset_idx = [name_to_cidx[nearest]]
                dem = demand_table[t_eff][nearest]
                lat = latency_fast(d_idx, subset_idx)
                best_local = (lat, subset_names, dem)

            lat, subset_names, dem = best_local
            est += lat
            r_tmp[dname] -= dem
            if r_tmp[dname] <= 0:
                if v_tmp[dname] > 0:
                    v_tmp[dname] -= 1
                    r_tmp[dname] = vehicle_capacity
                else:
                    r_tmp[dname] = 0
            inv_tmp[dname] -= dem
            for c in subset_names:
                if c in rem:
                    rem.remove(c)
            iters -= 1
            if not rem:
                break
    return est


# -----------------------------
# Value surrogate training utilities
# -----------------------------
_value_surrogate = None
if TORCH_OK:
    def generate_value_training_data(num_samples=400, seed=2025):
        rng_loc = random.Random(seed)
        data = []
        attempts = 0
        while len(data) < num_samples and attempts < num_samples * 10:
            attempts += 1
            t_next = rng_loc.randrange(0, time_horizon)
            available = [cid for cid in customer_ids if appear_time.get(cid, 0) <= t_next]
            if not available:
                continue
            rem_count = rng_loc.randint(1, len(available))
            remaining = rng_loc.sample(available, rem_count)
            inv_state = {d: rng_loc.randint(0, depot_capacity_per_depot) for d in depot_names}
            v_state = {d: rng_loc.randint(0, depot_capacity_per_depot // vehicle_capacity) for d in depot_names}
            r_state = {}
            for d in depot_names:
                base_cap = rng_loc.randint(0, vehicle_capacity)
                if base_cap == 0 and v_state[d] > 0 and rng_loc.random() < 0.3:
                    base_cap = vehicle_capacity
                r_state[d] = base_cap
            target = estimate_tail_value(remaining, inv_state, r_state, v_state, t_next)
            global_feat, cust_feat = build_state_tensors(t_next, remaining, inv_state, r_state, v_state)
            data.append((global_feat, cust_feat, float(target)))
        return data

    def train_value_surrogate(epochs=12, lr=1e-3, samples=400):
        dataset = generate_value_training_data(samples)
        if not dataset:
            return None
        model = Surrogate()
        opt = optim.Adam(model.parameters(), lr=lr)
        loss_fn = nn.MSELoss()
        model.train()
        for ep in range(epochs):
            random.shuffle(dataset)
            running = 0.0
            for global_feat, cust_feat, target in dataset:
                opt.zero_grad()
                pred = model(global_feat, cust_feat)
                loss = loss_fn(pred.view(-1), torch.tensor([target], dtype=torch.float32))
                loss.backward()
                opt.step()
                running += float(loss.item())
            if DEBUG_DIAG and ((ep + 1) % 4 == 0 or ep == epochs - 1):
                avg_loss = running / max(len(dataset), 1)
                print(f"[ValueSurrogate] epoch {ep+1}/{epochs} avg_loss={avg_loss:.4f}")
        model.eval()
        return model

    _value_surrogate = train_value_surrogate()

# -----------------------------
# Rollout policy (discounted total latency)
# -----------------------------
def surrogate_rollout_discounted_total():
    v_left = {d: depot_capacity_per_depot // vehicle_capacity for d in depot_names}
    r_left = {d: vehicle_capacity for d in depot_names}
    inv_left = {d: depot_capacity_per_depot for d in depot_names}

    total_disc, total_raw = 0.0, 0.0
    plan = []
    served = set()
    period_times = []

    for t in range(time_horizon):
        t_start = time.perf_counter()

        avail = [cid for cid in customer_ids if cid not in served and appear_time.get(cid, 0) <= t]
        if not avail:
            period_times.append(time.perf_counter() - t_start)
            continue

        best = None  # (qval, dname, subset_names, dem, lat)
        for dname in depot_names:
            if r_left[dname] <= 0 and v_left[dname] <= 0:
                continue
            cap = r_left[dname] if r_left[dname] > 0 else (vehicle_capacity if v_left[dname] > 0 else 0)
            inv = inv_left[dname]
            if cap <= 0 or inv <= 0:
                continue

            d_idx = depot_names.index(dname)
            pool  = nearest_k(avail, d_idx, K_NEAR)
            cands = cw_candidates(pool, d_idx, cap, inv, t, CAND_LIMIT)

            for subset_names in cands:
                dem = sum(demand_table[t][c] for c in subset_names)
                if dem <= 0 or dem > cap or dem > inv:
                    continue
                subset_idx = [name_to_cidx[c] for c in subset_names]
                lat = latency_fast(d_idx, subset_idx)
                remaining = [cid for cid in avail if cid not in subset_names]
                next_inv = dict(inv_left)
                next_inv[dname] = max(0, next_inv[dname] - dem)
                next_r = dict(r_left)
                next_v = dict(v_left)
                next_r[dname] = next_r.get(dname, 0) - dem
                if next_r[dname] <= 0:
                    if next_v.get(dname, 0) > 0:
                        next_v[dname] = next_v.get(dname, 0) - 1
                        next_r[dname] = vehicle_capacity
                    else:
                        next_r[dname] = 0
                if TORCH_OK and _value_surrogate is not None:
                    global_feat, cust_feat = build_state_tensors(t + 1, remaining, next_inv, next_r, next_v)
                    with torch.no_grad():
                        tail = float(_value_surrogate(global_feat, cust_feat))
                else:
                    tail = estimate_tail_value(remaining, next_inv, next_r, next_v, t+1)
                    
                qval = lat + discount_factor * tail
                cand = (qval, dname, subset_names, dem, lat)
                if (best is None or
                    qval < best[0] or
                    (qval == best[0] and dem > best[3]) or
                    (qval == best[0] and dem == best[3] and len(subset_names) > len(best[2]))):
                    best = cand

        # Fallback: reset a truck and serve nearest singleton
        if best is None:
            for dname in depot_names:
                if r_left[dname] <= 0 and v_left[dname] > 0:
                    v_left[dname] -= 1; r_left[dname] = vehicle_capacity
                cap = r_left[dname]; inv = inv_left[dname]
                if cap <= 0 or inv <= 0:
                    continue
                d_idx = depot_names.index(dname)
                nearest, bestd = None, float('inf')
                for cid in avail:
                    q = demand_table[t][cid]
                    if q <= 0 or q > cap or q > inv:
                        continue
                    cidx = name_to_cidx[cid]
                    d = W[d_idx, cidx]
                    if d < bestd:
                        bestd, nearest = d, cid
                if nearest is not None:
                    lat = latency_fast(d_idx, [name_to_cidx[nearest]])
                    dem = demand_table[t][nearest]
                    remaining = [cid for cid in avail if cid != nearest]
                    next_inv = dict(inv_left); next_inv[dname] = max(0, next_inv[dname] - dem)
                    next_r = dict(r_left); next_v = dict(v_left)
                    next_r[dname] = next_r.get(dname, 0) - dem
                    if next_r[dname] <= 0:
                        if next_v.get(dname, 0) > 0:
                            next_v[dname] = next_v.get(dname, 0) - 1
                            next_r[dname] = vehicle_capacity
                        else:
                            next_r[dname] = 0
                    if TORCH_OK and _value_surrogate is not None:
                        g_feat, c_feat = build_state_tensors(t + 1, remaining, next_inv, next_r, next_v)
                        with torch.no_grad():
                            tail = float(_value_surrogate(g_feat, c_feat))
                    else:
                        tail = estimate_tail_value(remaining, next_inv, next_r, next_v, t+1)
                    qval = lat + discount_factor * tail
                    best = (qval, dname, [nearest], dem, lat)
                    break

        if best is None:
            period_times.append(time.perf_counter() - t_start)
            continue

        qval, dname, chosen, dem, lat = best
        total_disc += (discount_factor ** t) * lat
        total_raw  += lat
        plan.append((t, dname, list(chosen), float(lat)))

        r_left[dname] -= dem
        if r_left[dname] <= 0:
            if v_left[dname] > 0:
                v_left[dname] -= 1
                r_left[dname] = vehicle_capacity
            else:
                r_left[dname] = 0
        inv_left[dname] -= dem
        for c in chosen:
            served.add(c)

        period_times.append(time.perf_counter() - t_start)

    # Cleanup phase to finish any stragglers
    t_clean = time_horizon
    remaining = [cid for cid in customer_ids if cid not in served]
    while remaining:
        progress = False
        for dname in depot_names:
            if not remaining:
                break
            cap = r_left[dname] if r_left[dname] > 0 else (vehicle_capacity if v_left[dname] > 0 else 0)
            inv = inv_left[dname]
            if cap <= 0 and v_left[dname] <= 0:
                continue

            d_idx = depot_names.index(dname)
            rem_sorted = sorted(remaining, key=lambda cid: W[d_idx, name_to_cidx[cid]])
            chosen, load = [], 0
            for cid in rem_sorted:
                q = demand_table[min(t_clean, time_horizon - 1)][cid]
                if q <= 0:
                    continue
                if load + q <= cap and load + q <= inv:
                    chosen.append(cid); load += q
                if load >= cap or load >= inv:
                    break
            if not chosen:
                continue

            subset_idx = [name_to_cidx[c] for c in chosen]
            # If huge set, cap to EXACT_K for latency calc (keeps runtime predictable)
            subset_for_latency = subset_idx if len(subset_idx) <= EXACT_K else subset_idx[:EXACT_K]
            lat_val = latency_fast(d_idx, subset_for_latency)

            total_disc += (discount_factor ** t_clean) * lat_val
            total_raw  += lat_val
            plan.append((t_clean, dname, chosen, float(lat_val)))

            r_left[dname] = max(0, cap - load)
            if r_left[dname] == 0 and v_left[dname] > 0:
                v_left[dname] -= 1; r_left[dname] = vehicle_capacity
            inv_left[dname] -= load
            for cid in chosen:
                if cid in remaining:
                    remaining.remove(cid)
                served.add(cid)
            progress = True

        if not progress:
            # Serve singletons by nearest feasible depot
            for cid in list(remaining):
                bestd, best_dep = float('inf'), None
                for dname in depot_names:
                    d_idx = depot_names.index(dname)
                    d = W[d_idx, name_to_cidx[cid]]
                    if d < bestd:
                        bestd, best_dep = d, dname
                if best_dep is None:
                    continue
                cap = r_left[best_dep] if r_left[best_dep] > 0 else (vehicle_capacity if v_left[best_dep] > 0 else 0)
                inv = inv_left[best_dep]
                q = demand_table[min(t_clean, time_horizon - 1)][cid]
                if q <= 0:
                    remaining.remove(cid); served.add(cid); continue
                if q > cap and v_left[best_dep] > 0:
                    v_left[best_dep] -= 1; r_left[best_dep] = vehicle_capacity; cap = r_left[best_dep]
                if q <= cap and q <= inv:
                    d_idx = depot_names.index(best_dep)
                    lat_val = latency_fast(d_idx, [name_to_cidx[cid]])
                    total_disc += (discount_factor ** t_clean) * lat_val
                    total_raw  += lat_val
                    plan.append((t_clean, best_dep, [cid], float(lat_val)))
                    r_left[best_dep] -= q
                    if r_left[best_dep] == 0 and v_left[best_dep] > 0:
                        v_left[best_dep] -= 1; r_left[best_dep] = vehicle_capacity
                    inv_left[best_dep] -= q
                    remaining.remove(cid); served.add(cid)
        t_clean += 1

    if period_times:
        avg = sum(period_times) / len(period_times)
        print(f"⏱️ Avg time/period: {avg:.4f}s | Max: {max(period_times):.4f}s | Periods: {len(period_times)}")

    return total_disc, total_raw, plan

# -----------------------------
# Run
# -----------------------------
if __name__ == "__main__":
    print(f"Latency surrogate (PyTorch) enabled: {bool('torch' in globals() and TORCH_OK and (_latency_surrogate is not None))}")
    print(f"Value surrogate (PyTorch) enabled:   {bool('torch' in globals() and TORCH_OK and (_value_surrogate is not None))}")
    if K_STOCHASTIC_LEGS > 0:
        def _leg_name(i): return depot_names[i] if i < D else customer_ids[i - D]
        print("Stochastic legs (Uniform[{:.2f},{:.2f}]):".format(MULT_LOWER, MULT_UPPER))
        for (a, b) in sorted(_selected_legs):
            print(f"  ({_leg_name(a)} , {_leg_name(b)})  x {_leg_factor[(a,b)]:.3f}")

    t0 = time.perf_counter()
    disc, raw, plan = surrogate_rollout_discounted_total()
    t1 = time.perf_counter()

    print(f"\nUndiscounted total latency: {raw:.6f}")
    print(f"Discounted objective:       {disc:.6f}")
    print(f"⏱️ Total runtime: {t1 - t0:.3f} seconds")

    # Served check + plan print
    served = {cid for (_, _, ss, _) in plan for cid in ss}
    rem = sorted(set(customer_ids) - served)
    if not rem:
        print("✅ All customers served.")
    else:
        print(f"⚠️ Not all customers served: {rem}")

    try:
        import pandas as pd
        df = pd.DataFrame([{"time": t, "depot": d, "served_customers": ss, "latency": lat}
                           for t, d, ss, lat in plan])
        print("\nPlan:")
        print(df.to_string(index=False))
    except Exception:
        print("\nPlan:")
        for t, d, ss, lat in plan:
            print(f" t={t:2d} depot={d} served={ss} lat={lat:.3f}")
BEAM = 8  # beam width for per-period selection (set 0 to disable)
USE_REGRET2 = True  # use regret-2 route builder for candidates


# ======================
# Candidate quality & local search helpers (drop-in)
# ======================
def build_route_regret2(customers, dist_ij, max_len=9):
    if DEBUG_DIAG:
        print(f"[regret2] start: candidates={len(customers)} max_len={max_len}")
    if not customers:
        return []
    pool = list(customers)
    first = pool.pop(0)
    if pool:
        second = min(pool, key=lambda c: dist_ij(first, c))
        route = [first, second]
        pool.remove(second)
    else:
        route = [first]
    while pool and len(route) < max_len:
        best_c, best_pos, best_regret, best_first = None, None, float("-inf"), None
        for c in pool:
            costs = []
            for k in range(len(route)+1):
                left = route[k-1] if k>0 else None
                right = route[k] if k<len(route) else None
                add = 0.0
                if left is not None: add += dist_ij(left, c)
                if right is not None: add += dist_ij(c, right)
                if left is not None and right is not None: add -= dist_ij(left, right)
                costs.append((add, k))
            costs.sort(key=lambda x: x[0])
            regret = (costs[1][0] if len(costs)>1 else costs[0][0]) - costs[0][0]
            if regret > best_regret or (regret == best_regret and (best_first is None or costs[0][0] < best_first)):
                best_c, best_pos, best_regret, best_first = c, costs[0][1], regret, costs[0][0]
        route.insert(best_pos, best_c)
        pool.remove(best_c)
    return route

def two_opt(route, dist_ij):
    r = list(route)
    if len(r) < 4:
        return r
    def rc(seq):
        return sum(dist_ij(seq[k], seq[k+1]) for k in range(len(seq)-1))
    best = r
    best_cost = rc(best)
    improved = True
    while improved:
        improved = False
        for i in range(1, len(best)-2):
            for j in range(i+1, len(best)-1):
                cand = best[:i] + list(reversed(best[i:j])) + best[j:]
                c = rc(cand)
                if c + 1e-9 < best_cost:
                    best, best_cost = cand, c
                    improved = True
                    break
            if improved: break
    return best

def or_opt_1(route, dist_ij, iters=20):
    r = list(route)
    if len(r) < 3:
        return r
    def rc(seq):
        return sum(dist_ij(seq[k], seq[k+1]) for k in range(len(seq)-1))
    best = r
    best_c = rc(best)
    for _ in range(iters):
        improved = False
        for i in range(len(best)):
            v = best[i]
            trial = best[:i] + best[i+1:]
            best_pos = None
            best_delta = float("inf")
            for k in range(len(trial)+1):
                left = trial[k-1] if k>0 else None
                right = trial[k] if k<len(trial) else None
                add = 0.0
                if left is not None: add += dist_ij(left, v)
                if right is not None: add += dist_ij(v, right)
                if left is not None and right is not None: add -= dist_ij(left, right)
                if add < best_delta:
                    best_delta, best_pos = add, k
            new = trial[:best_pos] + [v] + trial[best_pos:]
            new_c = rc(new)
            if new_c + 1e-9 < best_c:
                best, best_c = new, new_c
                improved = True
                break
        if not improved:
            break
    return best

# === Integration marker ===
### CALL_LOCAL_SEARCH_HERE ###
# After selecting a route R for a depot in period t:
# R = two_opt(R, dist_ij)
# R = or_opt_1(R, dist_ij, 20)


# ======================
# Beam-based period selection (scaffold)
# ======================
def select_period_with_beam(state, depots_order, generate_candidates, advance, Q_value, beam_width=8):
    if DEBUG_DIAG:
        print(f"[beam] width={beam_width}")
    frontier = [(0.0, state)]
    for d in depots_order:
        expanded = []
        for score, s in frontier:
            for cand in generate_candidates(s, d):
                q = Q_value(s, d, cand)
                s2 = advance(s, d, cand)
                expanded.append((score + q, s2))
        expanded.sort(key=lambda x: x[0])
        frontier = expanded[:beam_width]
    return min(frontier, key=lambda x: x[0])[1]

# ======================
# Convenience hook to apply local search and log proxy deltas
# ======================
def _route_arc_sum(route, dist_ij):
    if not route: return 0.0
    return sum(dist_ij(route[i], route[i+1]) for i in range(len(route)-1))

def apply_local_search(route, dist_ij, depot=None, period=None):
    """Run two_opt and or_opt_1; print arc-sum delta if DEBUG_DIAG."""
    r0 = list(route)
    c0 = _route_arc_sum(r0, dist_ij)
    r1 = two_opt(r0, dist_ij)
    r2 = or_opt_1(r1, dist_ij, iters=20)
    if DEBUG_DIAG:
        c2 = _route_arc_sum(r2, dist_ij)
        tag = f"d={depot} t={period}" if depot is not None and period is not None else ""
        print(f"[local-search] {tag} Δarc-sum={c0 - c2:.3f} len {len(r0)}→{len(r2)}")
    return r2
